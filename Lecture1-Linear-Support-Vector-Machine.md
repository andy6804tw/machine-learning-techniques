
## 前言
第一個如果我們今天有很多很多的特徵轉換 要使用的時候，我們怎麼好好地運用這些特徵轉換？ 更重要的是，這麼多的特徵轉換，可能會有複雜度的問題，我們怎麼控制這些複雜度的問 題。那這樣的想法，刺激了一個很有名的模型，叫做 Support Vector Machine， 支撐向量機的發展。

## [1-1 Large-Margin Separating Hyperplane](https://www.youtube.com/watch?v=8hak0XngnV0&list=PLXVfgk9fNX2IQOYPmqjqWsNUFl2kpk1U2&index=3)
### 哪一條線較好？為何最右邊？
透過測量誤差容忍度我們可以得到下面三種不同的線，就以 VC bound 來看，這三條線好像沒什麼差，其共通點都可以在訓練資料被完美的分開。如最右邊圖所示，如果我們的每一筆訓練資料跟線的距離，隔得越遠的話，那就表示我們的線，可以忍受越多的測量的誤差。因此我們希望訓練資料能夠離這些線越遠越好，這樣它就能夠容忍比較多的雜訊，同時能夠避免 overfitting 的情況發生。

![](https://i.imgur.com/X5j5btr.png)

> 定義一條線到底強不強壯就是，觀察離最接近的訓練資料到底有多遠。

從另一個角度來看就是觀察一條線能夠長到多胖，就是看從線往外面長出去，長到哪裡會碰到最接近的那些點。

![](https://i.imgur.com/BXnkTDH.png)

> 換句話說定義一條線到底強不強壯就是，就是比較胖的線。

因此我們想要找出來某一條線，這條線要滿足兩個特性。一個是跟 PLA 找出來的線一樣，必須將所有的訓練資料圈圈叉叉都好好的分開。接著在把它分開以後，在那麽多條把它分開的線裏面，我們需要選擇一條最胖的線(邊界最大)，就是最強壯最強固的線。至於該如何定義它到底有多胖呢？最簡單的方式就是把這條線與每一個點的距離都算一算，取最小的距離作為判斷依據。

![](https://i.imgur.com/ATtROj3.png)

- separating hyperplane
- find largest-margin

## 重點整理
- 我們要找出的一條線需要與每個點都越遠越好，使得可以容忍較大的測量誤差。
- 定義一條線到底有多強壯就是，一條線的邊界有多胖，或者觀察離直線最近的點距離是多少？
